{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports and set magics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(response: requests.Response):\n",
    "    \"\"\"\n",
    "    Creates or appends a log-file with information from a requests.get()-call.\n",
    "    \n",
    "    The information gathered is:\n",
    "    - - - - - - - -\n",
    "        timestamp   :   Current local time.\n",
    "        status_code :   Status code from requests call.\n",
    "        length      :   Length of the HTML-string.\n",
    "        output_path :   Current working directory.\n",
    "        url         :   The URL of the response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open or create the csv file\n",
    "    if os.path.isfile('log'):\n",
    "        log = open('log','a')\n",
    "    else: \n",
    "        log = open('log','w')\n",
    "        header = ['timestamp', 'status_code', 'length', 'output_file', 'url'] # Header names\n",
    "        log.write(';'.join(header) + \"\\n\")\n",
    "        \n",
    "    # Gather log information\n",
    "    status_code = response.status_code # Status code from the request result\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) # Local time\n",
    "    length = len(response.text) # Length of the HTML-string\n",
    "    output_path = os.getcwd() # Output path\n",
    "    url = response.url # URL-string\n",
    "    \n",
    "    # Open the log file and append the gathered log information\n",
    "    with open('log','a') as log:\n",
    "        log.write(f'{timestamp};{status_code};{length};{output_path};{url}' + \"\\n\") \n",
    "\n",
    "\n",
    "def create_url(page: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a PolitiFact URL with the given pagenumber.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    page (int) :    Pagenumber for the PolitiFact website.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    url (str)  :    URL of the PolitiFact website for given page. \n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://www.politifact.com/factchecks/list/?page={page}' # Construct url with f-string\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_soup(url: str, header: dict) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Constructs a HTML-string from a request of the given URL. \n",
    "    Requests are logged, see log(). \n",
    "\n",
    "    Input:\n",
    "    - - - - - - - - \n",
    "    url (str)     :    URL of the website to receive the HTML-string from. \\n\n",
    "    header (dict) :    Dictionary to send in the query string for the request.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    soup (BeautifulSoup) :  HTML-string in the class of BeutifulSoup with 'lxml' parser.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url, headers=header) # Request\n",
    "    log(response) # Log \n",
    "    soup = BeautifulSoup(response.content, 'lxml') # Convert to response to HTML\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def extract_articles(soup: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    Extracts articles from HTML-string from the PolitiFact website.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    soup (BeautifulSoup) : HTML-string from the PolitiFact website.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    list_of_articles (list) : A list of all articles in the given soup. \\n\n",
    "                              Each element is an article of data structure as BeautifulSoup.\n",
    "    \"\"\"\n",
    "    \n",
    "    articles = soup.find(class_='o-listicle__list') # Find section with articles\n",
    "    list_of_articles = articles.find_all('li') # Find all articles as a list\n",
    "\n",
    "    return list_of_articles\n",
    "\n",
    "\n",
    "def extract_info(article: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    Extracts all relevant information from an article on the PolitiFact website.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - - \n",
    "    article (BeautifulSoup) :  Article to extract data from, see extract_articles().\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    [name_txt, name_href, description_txt, quote_txt, quote_href, meter, footer] (list) \\n \n",
    "    The name and URL of the quoted person, the description of the quote, the quote itself \\n\n",
    "    and link hereof, the truthfulness index, and information on the article in string-format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Statement name \n",
    "    name = article.find(class_='m-statement__name')\n",
    "    name_txt = name.text # name \n",
    "    name_href = name['href'] # href\n",
    "\n",
    "    # Statement description\n",
    "    description_txt = article.find(class_='m-statement__desc').text\n",
    "\n",
    "    # Statement quote\n",
    "    quote = article.find(class_='m-statement__quote').a\n",
    "    quote_txt = quote.text # name \n",
    "    quote_href = quote['href'] # href\n",
    "\n",
    "    # Statement meter\n",
    "    meter = article.find(class_='m-statement__meter').div.img['alt']\n",
    "\n",
    "    # Statement footer\n",
    "    footer = article.find(class_='m-statement__footer').text\n",
    "\n",
    "    return [name_txt, name_href, description_txt, quote_txt, quote_href, meter, footer]\n",
    "\n",
    "\n",
    "def data_politifact(startpage: int, endpage: int, header: dict) -> list:\n",
    "    \"\"\"\n",
    "    Compound function that scrapes an interval of pages from PolitiFact and extracts information for analysis. \\n\n",
    "    Saves extracted information for each page in '/data'-folder as CSV, and logs requests in 'log'. \n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    startpage (int) :  The first page to scrape. \\n\n",
    "    endpage   (int) :  The last page to scrape. \\n\n",
    "    header    (dict):  Dictionary to send in the query string for the request.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    list_of_dfs (list) : A list of pandas.DataFrame containing the extracted information from each page.\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_dfs = [] # initialize empty list for dataframes\n",
    "\n",
    "    # Loop through pages and track progress with tqdm\n",
    "    for page in tqdm.tqdm(range(startpage, endpage+1)):\n",
    "        url = create_url(page) # create url\n",
    "\n",
    "        try: # circumvent problem with empty pages\n",
    "            soup = get_soup(url, header) # construct html\n",
    "            articles = extract_articles(soup) # extract articles \n",
    "\n",
    "            output = [] # initialize empty for articles \n",
    "\n",
    "            # Loop through articles \n",
    "            for article in articles:\n",
    "                info = extract_info(article) # extract relevant information\n",
    "                output.append(info) # append output\n",
    "\n",
    "        except: # skip page\n",
    "            continue\n",
    "\n",
    "        # Create DataFrame\n",
    "        output_df = pd.DataFrame(output, columns=['name_txt', 'name_href', 'description_txt', 'quote_txt', 'quote_href', 'meter', 'footer'])\n",
    "\n",
    "        # Create data-folder if it doesn't exist\n",
    "        path = os.getcwd() + '/data/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        # Save CSV-file and append list of DataFrames\n",
    "        output_df.to_csv(path + f'data_p{page}', index=False) # save csv\n",
    "        list_of_dfs.append(output_df) # append df\n",
    "\n",
    "        \n",
    "\n",
    "        time.sleep(0.5) # sleep for 0.5 sec \n",
    "\n",
    "    return list_of_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape all pages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do *one* of the following three:\n",
    "1. Download all data. **NB!** Takes ~30 minutes.\n",
    "2. Load data from data folder if data has been downloaded.\n",
    "3. Load full dataset if data has been downloaded and concatenated.\n",
    "\n",
    "Option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "header = {  'name_1':'Marius Heltberg Lassen'   ,'email_1':'pgb206@alumni.ku.dk', \n",
    "            'name_2':'Jørgen Baun Høst'         ,'email_2':'pjz633@alumni.ku.dk',\n",
    "            'intention':'Train supervised ML model for academic purposes' } # state names and (non-commerical/academic) intentions for data scraping\n",
    "#dfs = data_politifact(1, 728, header)\n",
    "data_full = pd.concat(dfs)\n",
    "data_full.to_csv('data_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir('data'):\n",
    "    dfs.append(pd.read_csv('data/' + file))\n",
    "data_full = pd.concat(dfs)\n",
    "data_full.to_csv('data_full', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv('data_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_txt</th>\n",
       "      <th>name_href</th>\n",
       "      <th>description_txt</th>\n",
       "      <th>quote_txt</th>\n",
       "      <th>quote_href</th>\n",
       "      <th>meter</th>\n",
       "      <th>footer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nRobert Hurt\\n</td>\n",
       "      <td>/personalities/robert-hurt/</td>\n",
       "      <td>\\nstated on April 16, 2015 in a statement.:\\n</td>\n",
       "      <td>\\nSays the estate tax, \"in many cases,\" forces...</td>\n",
       "      <td>/factchecks/2015/may/03/robert-hurt/hurt-amiss...</td>\n",
       "      <td>false</td>\n",
       "      <td>\\nBy Warren Fiske • May 3, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nMarco Rubio\\n</td>\n",
       "      <td>/personalities/marco-rubio/</td>\n",
       "      <td>\\nstated on April 13, 2015 in an interview on ...</td>\n",
       "      <td>\\n\"The Iranians are now saying that what we're...</td>\n",
       "      <td>/factchecks/2015/may/01/marco-rubio/iran-unite...</td>\n",
       "      <td>true</td>\n",
       "      <td>\\nBy Lauren Carroll • May 1, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCity of Atlanta\\n</td>\n",
       "      <td>/personalities/city-atlanta/</td>\n",
       "      <td>\\nstated on August 8, 2014 in press release:\\n</td>\n",
       "      <td>\\nTyler Perry’s plan to turn a majority of the...</td>\n",
       "      <td>/factchecks/2015/may/01/city-atlanta/Studio-pl...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>\\nBy Nancy Badertscher • May 1, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nRepresent.us\\n</td>\n",
       "      <td>/personalities/representus/</td>\n",
       "      <td>\\nstated on April 30, 2015 in a meme on social...</td>\n",
       "      <td>\\n\"The U.S. representatives that voted to keep...</td>\n",
       "      <td>/factchecks/2015/apr/30/representus/did-lawmak...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>\\nBy Louis Jacobson • April 30, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSteve Crisafulli\\n</td>\n",
       "      <td>/personalities/steve-crisafulli/</td>\n",
       "      <td>\\nstated on April 28, 2015 in an op-ed in the ...</td>\n",
       "      <td>\\n\"If we choose Obamacare expansion, 600,000 w...</td>\n",
       "      <td>/factchecks/2015/apr/30/steve-crisafulli/crisa...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>\\nBy Joshua Gillin • April 30, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21638</th>\n",
       "      <td>\\nMarco Rubio\\n</td>\n",
       "      <td>/personalities/marco-rubio/</td>\n",
       "      <td>\\nstated on October 17, 2016 in a U.S. Senate ...</td>\n",
       "      <td>\\n\"In about three weeks over a half million Fl...</td>\n",
       "      <td>/factchecks/2016/oct/18/marco-rubio/marco-rubi...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>\\nBy Amy Sherman • October 18, 2016\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21639</th>\n",
       "      <td>\\nBrad Schneider\\n</td>\n",
       "      <td>/personalities/brad-schneider/</td>\n",
       "      <td>\\nstated on September 16, 2016 in a campaign t...</td>\n",
       "      <td>\\nSays Republican U.S. Rep. Bob Dold \"continue...</td>\n",
       "      <td>/factchecks/2016/oct/18/brad-schneider/schneid...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>\\nBy Anna Bruzgulis • October 18, 2016\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21640</th>\n",
       "      <td>\\nPatrick Murphy\\n</td>\n",
       "      <td>/personalities/patrick-murphy/</td>\n",
       "      <td>\\nstated on October 17, 2016 in a U.S. Senate ...</td>\n",
       "      <td>\\n\"When asked about equal pay for women, (Rubi...</td>\n",
       "      <td>/factchecks/2016/oct/18/patrick-murphy/rubio-c...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>\\nBy Joshua Gillin • October 18, 2016\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21641</th>\n",
       "      <td>\\nDonald Trump\\n</td>\n",
       "      <td>/personalities/donald-trump/</td>\n",
       "      <td>\\nstated on October 13, 2016 in a speech:\\n</td>\n",
       "      <td>\\nSays Hillary Clinton was \"let off the hook\" ...</td>\n",
       "      <td>/factchecks/2016/oct/18/donald-trump/fbi-direc...</td>\n",
       "      <td>false</td>\n",
       "      <td>\\nBy C. Eugene Emery Jr. • October 18, 2016\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21642</th>\n",
       "      <td>\\nPatrick Murphy\\n</td>\n",
       "      <td>/personalities/patrick-murphy/</td>\n",
       "      <td>\\nstated on October 17, 2016 in a U.S. Senate ...</td>\n",
       "      <td>\\n\"Marco Rubio made it clear: Not only does he...</td>\n",
       "      <td>/factchecks/2016/oct/18/patrick-murphy/patrick...</td>\n",
       "      <td>true</td>\n",
       "      <td>\\nBy Allison Graves • October 18, 2016\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21643 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name_txt                         name_href  \\\n",
       "0           \\nRobert Hurt\\n       /personalities/robert-hurt/   \n",
       "1           \\nMarco Rubio\\n       /personalities/marco-rubio/   \n",
       "2       \\nCity of Atlanta\\n      /personalities/city-atlanta/   \n",
       "3          \\nRepresent.us\\n       /personalities/representus/   \n",
       "4      \\nSteve Crisafulli\\n  /personalities/steve-crisafulli/   \n",
       "...                     ...                               ...   \n",
       "21638       \\nMarco Rubio\\n       /personalities/marco-rubio/   \n",
       "21639   \\nBrad Schneider\\n     /personalities/brad-schneider/   \n",
       "21640    \\nPatrick Murphy\\n    /personalities/patrick-murphy/   \n",
       "21641      \\nDonald Trump\\n      /personalities/donald-trump/   \n",
       "21642    \\nPatrick Murphy\\n    /personalities/patrick-murphy/   \n",
       "\n",
       "                                         description_txt  \\\n",
       "0          \\nstated on April 16, 2015 in a statement.:\\n   \n",
       "1      \\nstated on April 13, 2015 in an interview on ...   \n",
       "2         \\nstated on August 8, 2014 in press release:\\n   \n",
       "3      \\nstated on April 30, 2015 in a meme on social...   \n",
       "4      \\nstated on April 28, 2015 in an op-ed in the ...   \n",
       "...                                                  ...   \n",
       "21638  \\nstated on October 17, 2016 in a U.S. Senate ...   \n",
       "21639  \\nstated on September 16, 2016 in a campaign t...   \n",
       "21640  \\nstated on October 17, 2016 in a U.S. Senate ...   \n",
       "21641        \\nstated on October 13, 2016 in a speech:\\n   \n",
       "21642  \\nstated on October 17, 2016 in a U.S. Senate ...   \n",
       "\n",
       "                                               quote_txt  \\\n",
       "0      \\nSays the estate tax, \"in many cases,\" forces...   \n",
       "1      \\n\"The Iranians are now saying that what we're...   \n",
       "2      \\nTyler Perry’s plan to turn a majority of the...   \n",
       "3      \\n\"The U.S. representatives that voted to keep...   \n",
       "4      \\n\"If we choose Obamacare expansion, 600,000 w...   \n",
       "...                                                  ...   \n",
       "21638  \\n\"In about three weeks over a half million Fl...   \n",
       "21639  \\nSays Republican U.S. Rep. Bob Dold \"continue...   \n",
       "21640  \\n\"When asked about equal pay for women, (Rubi...   \n",
       "21641  \\nSays Hillary Clinton was \"let off the hook\" ...   \n",
       "21642  \\n\"Marco Rubio made it clear: Not only does he...   \n",
       "\n",
       "                                              quote_href        meter  \\\n",
       "0      /factchecks/2015/may/03/robert-hurt/hurt-amiss...        false   \n",
       "1      /factchecks/2015/may/01/marco-rubio/iran-unite...         true   \n",
       "2      /factchecks/2015/may/01/city-atlanta/Studio-pl...    half-true   \n",
       "3      /factchecks/2015/apr/30/representus/did-lawmak...  mostly-true   \n",
       "4      /factchecks/2015/apr/30/steve-crisafulli/crisa...  mostly-true   \n",
       "...                                                  ...          ...   \n",
       "21638  /factchecks/2016/oct/18/marco-rubio/marco-rubi...    half-true   \n",
       "21639  /factchecks/2016/oct/18/brad-schneider/schneid...    half-true   \n",
       "21640  /factchecks/2016/oct/18/patrick-murphy/rubio-c...    half-true   \n",
       "21641  /factchecks/2016/oct/18/donald-trump/fbi-direc...        false   \n",
       "21642  /factchecks/2016/oct/18/patrick-murphy/patrick...         true   \n",
       "\n",
       "                                              footer  \n",
       "0                  \\nBy Warren Fiske • May 3, 2015\\n  \n",
       "1                \\nBy Lauren Carroll • May 1, 2015\\n  \n",
       "2             \\nBy Nancy Badertscher • May 1, 2015\\n  \n",
       "3             \\nBy Louis Jacobson • April 30, 2015\\n  \n",
       "4              \\nBy Joshua Gillin • April 30, 2015\\n  \n",
       "...                                              ...  \n",
       "21638          \\nBy Amy Sherman • October 18, 2016\\n  \n",
       "21639       \\nBy Anna Bruzgulis • October 18, 2016\\n  \n",
       "21640        \\nBy Joshua Gillin • October 18, 2016\\n  \n",
       "21641  \\nBy C. Eugene Emery Jr. • October 18, 2016\\n  \n",
       "21642       \\nBy Allison Graves • October 18, 2016\\n  \n",
       "\n",
       "[21643 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = 'https://politifact.com'\n",
    "url_add = data_full['quote_href'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_full = url_base+url_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://politifact.com/factchecks/2015/may/03/robert-hurt/hurt-amiss-linking-estate-tax-small-farm-businesse/'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {  'name_1':'Marius Heltberg Lassen'   ,'email_1':'pgb206@alumni.ku.dk', \n",
    "            'name_2':'Jørgen Baun Høst'         ,'email_2':'pjz633@alumni.ku.dk',\n",
    "            'intention':'Train supervised ML model for academic purposes' } # state names and (non-commerical/academic) intentions for data scraping\n",
    "\n",
    "soup = get_soup(url_full, header=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_soup = soup.find(class_='m-list m-list--horizontal')\n",
    "tag_soup = tag_soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nAgriculture\\n',\n",
       " '\\nFamilies\\n',\n",
       " '\\nSmall Business\\n',\n",
       " '\\nTaxes\\n',\n",
       " '\\nVirginia\\n',\n",
       " '\\n\\n\\n\\nRobert Hurt\\n']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_list = []\n",
    "i=0\n",
    "\n",
    "for tag in tag_soup:\n",
    "    tags_list.append(tag_soup[i].text) \n",
    "    #Make it a dictionary with quote_href as key?\n",
    "    #Remove last tag (this is a 'person' tag, can be found as 'name_txt')\n",
    "    i+=1\n",
    "\n",
    "tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_header = soup.find(class_='c-title c-title--subline').text #conclusion by journalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_block = soup.find(class_='m-textblock') #Find article's body text\n",
    "text_body = []\n",
    "\n",
    "for paragraph in text_block.find_all('p'): #Find all paragraphs in article\n",
    "    text_body.append(paragraph.text) #append them to list\n",
    "\n",
    "text_body=' '.join(text_body) #Convert to a single string\n",
    "text_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('U.S. Rep. Robert Hurt, \"Robert Hurt Votes to Repeal death Tax and Restore Fairness for American Families,\" April 16, 2015.',\n",
       "  'http://hurt.house.gov/index.cfm/press-releases?ID=7F70CEC4-2048-494A-AC84-CC1AEA2EAA3F'),\n",
       " ('Email from Abigail Sigler, press secretary for Hurt, April 23, 2015.',\n",
       "  'No link')]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_block = soup.find(class_='m-superbox__content')\\\n",
    "                    .find_all('p') #Find article's source block and paragraphs\n",
    "source_body = []\n",
    "source_link = []\n",
    "\n",
    "for paragraph in source_block:\n",
    "    source_body.append(paragraph.text) #Find text in source paragraph and append\n",
    "\n",
    "for paragraph in source_block:\n",
    "    try:\n",
    "        source_link.append(paragraph.a['href']) #append link if it's there\n",
    "    except:\n",
    "        continue\n",
    "    source_link.append('No link') #Append 'no link' if there's no url. \n",
    "\n",
    "#Is this how we wanna do it??\n",
    "        \n",
    "sources = list(zip(source_body,source_link))\n",
    "sources[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "054e95b4819972eba8d406807e822e3be9cca805528e86310f8e3ac8dc287778"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
