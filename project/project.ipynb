{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  imports and set magics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(response: requests.Response):\n",
    "    \"\"\"\n",
    "    Creates or appends a log-file with information from a requests.get()-call.\n",
    "    \n",
    "    The information gathered is:\n",
    "    - - - - - - - -\n",
    "        timestamp   :   Current local time.\n",
    "        status_code :   Status code from requests call.\n",
    "        length      :   Length of the HTML-string.\n",
    "        output_path :   Current working directory.\n",
    "        url         :   The URL of the response.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open or create the csv file\n",
    "    if os.path.isfile('log'):\n",
    "        log = open('log','a')\n",
    "    else: \n",
    "        log = open('log','w')\n",
    "        header = ['timestamp', 'status_code', 'length', 'output_file', 'url'] # Header names\n",
    "        log.write(';'.join(header) + \"\\n\")\n",
    "        \n",
    "    # Gather log information\n",
    "    status_code = response.status_code # Status code from the request result\n",
    "    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())) # Local time\n",
    "    length = len(response.text) # Length of the HTML-string\n",
    "    output_path = os.getcwd() # Output path\n",
    "    url = response.url # URL-string\n",
    "    \n",
    "    # Open the log file and append the gathered log information\n",
    "    with open('log','a') as log:\n",
    "        log.write(f'{timestamp};{status_code};{length};{output_path};{url}' + \"\\n\") \n",
    "\n",
    "\n",
    "def create_url(page: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a PolitiFact URL with the given pagenumber.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    page (int) :    Pagenumber for the PolitiFact website.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    url (str)  :    URL of the PolitiFact website for given page. \n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://www.politifact.com/factchecks/list/?page={page}' # Construct url with f-string\n",
    "\n",
    "    return url\n",
    "\n",
    "\n",
    "def get_soup(url: str, header: dict) -> BeautifulSoup:\n",
    "    \"\"\"\n",
    "    Constructs a HTML-string from a request of the given URL. \n",
    "    Requests are logged, see log(). \n",
    "\n",
    "    Input:\n",
    "    - - - - - - - - \n",
    "    url (str)     :    URL of the website to receive the HTML-string from. \\n\n",
    "    header (dict) :    Dictionary to send in the query string for the request.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    soup (BeautifulSoup) :  HTML-string in the class of BeutifulSoup with 'lxml' parser.\n",
    "    \"\"\"\n",
    "\n",
    "    response = requests.get(url, headers=header) # Request\n",
    "    log(response) # Log \n",
    "    soup = BeautifulSoup(response.content, 'lxml') # Convert to response to HTML\n",
    "\n",
    "    return soup\n",
    "\n",
    "\n",
    "def extract_articles(soup: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    Extracts articles from HTML-string from the PolitiFact website.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    soup (BeautifulSoup) : HTML-string from the PolitiFact website.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    list_of_articles (list) : A list of all articles in the given soup. \\n\n",
    "                              Each element is an article of data structure as BeautifulSoup.\n",
    "    \"\"\"\n",
    "    \n",
    "    articles = soup.find(class_='o-listicle__list') # Find section with articles\n",
    "    list_of_articles = articles.find_all('li') # Find all articles as a list\n",
    "\n",
    "    return list_of_articles\n",
    "\n",
    "\n",
    "def extract_info(article: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    Extracts all relevant information from an article on the PolitiFact website.\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - - \n",
    "    article (BeautifulSoup) :  Article to extract data from, see extract_articles().\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - - \n",
    "    [name_txt, name_href, description_txt, quote_txt, quote_href, meter, footer] (list) \\n \n",
    "    The name and URL of the quoted person, the description of the quote, the quote itself \\n\n",
    "    and link hereof, the truthfulness index, and information on the article in string-format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Statement name \n",
    "    name = article.find(class_='m-statement__name')\n",
    "    name_txt = name.text # name \n",
    "    name_href = name['href'] # href\n",
    "\n",
    "    # Statement description\n",
    "    description_txt = article.find(class_='m-statement__desc').text\n",
    "\n",
    "    # Statement quote\n",
    "    quote = article.find(class_='m-statement__quote').a\n",
    "    quote_txt = quote.text # name \n",
    "    quote_href = quote['href'] # href\n",
    "\n",
    "    # Statement meter\n",
    "    meter = article.find(class_='m-statement__meter').div.img['alt']\n",
    "\n",
    "    # Statement footer\n",
    "    footer = article.find(class_='m-statement__footer').text\n",
    "\n",
    "    return [name_txt, name_href, description_txt, quote_txt, quote_href, meter, footer]\n",
    "\n",
    "\n",
    "def data_politifact(startpage: int, endpage: int, header: dict) -> list:\n",
    "    \"\"\"\n",
    "    Compound function that scrapes an interval of pages from PolitiFact and extracts information for analysis. \\n\n",
    "    Saves extracted information for each page in '/data'-folder as CSV, and logs requests in 'log'. \n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    startpage (int) :  The first page to scrape. \\n\n",
    "    endpage   (int) :  The last page to scrape. \\n\n",
    "    header    (dict):  Dictionary to send in the query string for the request.\n",
    "\n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    list_of_dfs (list) : A list of pandas.DataFrame containing the extracted information from each page.\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_dfs = [] # initialize empty list for dataframes\n",
    "\n",
    "    # Loop through pages and track progress with tqdm\n",
    "    for page in tqdm.tqdm(range(startpage, endpage+1)):\n",
    "        url = create_url(page) # create url\n",
    "\n",
    "        try: # circumvent problem with empty pages\n",
    "            soup = get_soup(url, header) # construct html\n",
    "            articles = extract_articles(soup) # extract articles \n",
    "\n",
    "            output = [] # initialize empty for articles \n",
    "\n",
    "            # Loop through articles \n",
    "            for article in articles:\n",
    "                info = extract_info(article) # extract relevant information\n",
    "                output.append(info) # append output\n",
    "\n",
    "        except: # skip page\n",
    "            continue\n",
    "\n",
    "        # Create DataFrame\n",
    "        output_df = pd.DataFrame(output, columns=['name_txt', 'name_href', 'description_txt', 'quote_txt', 'quote_href', 'meter', 'footer'])\n",
    "\n",
    "        # Create data-folder if it doesn't exist\n",
    "        path = os.getcwd() + '/data/'\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        # Save CSV-file and append list of DataFrames\n",
    "        output_df.to_csv(path + f'data_p{page}', index=False) # save csv\n",
    "        list_of_dfs.append(output_df) # append df\n",
    "\n",
    "        \n",
    "\n",
    "        time.sleep(0.5) # sleep for 0.5 sec \n",
    "\n",
    "    return list_of_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape all pages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do *one* of the following three:\n",
    "1. Download all data. **NB!** Takes ~30 minutes.\n",
    "2. Load data from data folder if data has been downloaded.\n",
    "3. Load full dataset if data has been downloaded and concatenated.\n",
    "\n",
    "Option 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "header = {  'name_1':'Marius Heltberg Lassen'   ,'email_1':'pgb206@alumni.ku.dk', \n",
    "            'name_2':'Jørgen Baun Høst'         ,'email_2':'pjz633@alumni.ku.dk',\n",
    "            'intention':'Train supervised ML model for academic purposes' } # state names and (non-commerical/academic) intentions for data scraping\n",
    "#dfs = data_politifact(1, 728, header)\n",
    "data_full = pd.concat(dfs)\n",
    "data_full.to_csv('data_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in os.listdir('data'):\n",
    "    dfs.append(pd.read_csv('data/' + file))\n",
    "data_full = pd.concat(dfs)\n",
    "data_full.to_csv('data_full', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_full = pd.read_csv('data_full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_txt</th>\n",
       "      <th>name_href</th>\n",
       "      <th>description_txt</th>\n",
       "      <th>quote_txt</th>\n",
       "      <th>quote_href</th>\n",
       "      <th>meter</th>\n",
       "      <th>footer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nRobert Hurt\\n</td>\n",
       "      <td>/personalities/robert-hurt/</td>\n",
       "      <td>\\nstated on April 16, 2015 in a statement.:\\n</td>\n",
       "      <td>\\nSays the estate tax, \"in many cases,\" forces...</td>\n",
       "      <td>/factchecks/2015/may/03/robert-hurt/hurt-amiss...</td>\n",
       "      <td>false</td>\n",
       "      <td>\\nBy Warren Fiske • May 3, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nMarco Rubio\\n</td>\n",
       "      <td>/personalities/marco-rubio/</td>\n",
       "      <td>\\nstated on April 13, 2015 in an interview on ...</td>\n",
       "      <td>\\n\"The Iranians are now saying that what we're...</td>\n",
       "      <td>/factchecks/2015/may/01/marco-rubio/iran-unite...</td>\n",
       "      <td>true</td>\n",
       "      <td>\\nBy Lauren Carroll • May 1, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCity of Atlanta\\n</td>\n",
       "      <td>/personalities/city-atlanta/</td>\n",
       "      <td>\\nstated on August 8, 2014 in press release:\\n</td>\n",
       "      <td>\\nTyler Perry’s plan to turn a majority of the...</td>\n",
       "      <td>/factchecks/2015/may/01/city-atlanta/Studio-pl...</td>\n",
       "      <td>half-true</td>\n",
       "      <td>\\nBy Nancy Badertscher • May 1, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nRepresent.us\\n</td>\n",
       "      <td>/personalities/representus/</td>\n",
       "      <td>\\nstated on April 30, 2015 in a meme on social...</td>\n",
       "      <td>\\n\"The U.S. representatives that voted to keep...</td>\n",
       "      <td>/factchecks/2015/apr/30/representus/did-lawmak...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>\\nBy Louis Jacobson • April 30, 2015\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nSteve Crisafulli\\n</td>\n",
       "      <td>/personalities/steve-crisafulli/</td>\n",
       "      <td>\\nstated on April 28, 2015 in an op-ed in the ...</td>\n",
       "      <td>\\n\"If we choose Obamacare expansion, 600,000 w...</td>\n",
       "      <td>/factchecks/2015/apr/30/steve-crisafulli/crisa...</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>\\nBy Joshua Gillin • April 30, 2015\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name_txt                         name_href  \\\n",
       "0       \\nRobert Hurt\\n       /personalities/robert-hurt/   \n",
       "1       \\nMarco Rubio\\n       /personalities/marco-rubio/   \n",
       "2   \\nCity of Atlanta\\n      /personalities/city-atlanta/   \n",
       "3      \\nRepresent.us\\n       /personalities/representus/   \n",
       "4  \\nSteve Crisafulli\\n  /personalities/steve-crisafulli/   \n",
       "\n",
       "                                     description_txt  \\\n",
       "0      \\nstated on April 16, 2015 in a statement.:\\n   \n",
       "1  \\nstated on April 13, 2015 in an interview on ...   \n",
       "2     \\nstated on August 8, 2014 in press release:\\n   \n",
       "3  \\nstated on April 30, 2015 in a meme on social...   \n",
       "4  \\nstated on April 28, 2015 in an op-ed in the ...   \n",
       "\n",
       "                                           quote_txt  \\\n",
       "0  \\nSays the estate tax, \"in many cases,\" forces...   \n",
       "1  \\n\"The Iranians are now saying that what we're...   \n",
       "2  \\nTyler Perry’s plan to turn a majority of the...   \n",
       "3  \\n\"The U.S. representatives that voted to keep...   \n",
       "4  \\n\"If we choose Obamacare expansion, 600,000 w...   \n",
       "\n",
       "                                          quote_href        meter  \\\n",
       "0  /factchecks/2015/may/03/robert-hurt/hurt-amiss...        false   \n",
       "1  /factchecks/2015/may/01/marco-rubio/iran-unite...         true   \n",
       "2  /factchecks/2015/may/01/city-atlanta/Studio-pl...    half-true   \n",
       "3  /factchecks/2015/apr/30/representus/did-lawmak...  mostly-true   \n",
       "4  /factchecks/2015/apr/30/steve-crisafulli/crisa...  mostly-true   \n",
       "\n",
       "                                   footer  \n",
       "0       \\nBy Warren Fiske • May 3, 2015\\n  \n",
       "1     \\nBy Lauren Carroll • May 1, 2015\\n  \n",
       "2  \\nBy Nancy Badertscher • May 1, 2015\\n  \n",
       "3  \\nBy Louis Jacobson • April 30, 2015\\n  \n",
       "4   \\nBy Joshua Gillin • April 30, 2015\\n  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define article data extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_data(article: BeautifulSoup) -> list:\n",
    "    \"\"\"\n",
    "    A function that scrapes each individual article for relevant data. \\n\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    article (BeautifulSoup) : BeatifulSoup element of article. \\n\n",
    "    \n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    [tags,sub_header,text_body,sources, quote_href] : A list of of all relevant data from each politifact article.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    quote_href = article.find('meta', property='og:url')['content']\n",
    "    quote_href = quote_href.replace('https://www.politifact.com', '') #Extract the quote_href from the meta data\n",
    "\n",
    "    tag_soup = article.find(class_='m-list m-list--horizontal')\\\n",
    "        .find_all('a') #Find all tags\n",
    "    \n",
    "    list_of_tags = []\n",
    "    \n",
    "    i=0\n",
    "    \n",
    "    for tag in tag_soup:\n",
    "        list_of_tags.append(tag_soup[i]['title']) \n",
    "        #Make it a dictionary with quote_href as key?\n",
    "        #Remove last tag (this is a 'person' tag, can be found as 'name_txt')\n",
    "        i+=1\n",
    "    \n",
    "    tags = {quote_href: list_of_tags} #Create dictionary w/list of tags and quote_href as key \n",
    "\n",
    "    sub_header = article.find(class_='c-title c-title--subline').text #conclusion by journalist\n",
    "\n",
    "    text_block = article.find(class_='m-textblock') #Find article's body text\n",
    "    text_body = []\n",
    "\n",
    "    for paragraph in text_block.find_all('p'): #Find all paragraphs in article\n",
    "        text_body.append(paragraph.text) #append them to list\n",
    "\n",
    "    text_body=' '.join(text_body) #Convert to a single string\n",
    "\n",
    "    source_block = article.find(class_='m-superbox__content')\\\n",
    "                    .find_all('p') #Find article's source block and paragraphs\n",
    "    \n",
    "    source_body = []\n",
    "    source_link = []\n",
    "\n",
    "    for paragraph in source_block:\n",
    "        source_body.append(paragraph.text) #Find text in source paragraph and append\n",
    "\n",
    "    for paragraph in source_block:\n",
    "        try:\n",
    "            source_link.append(paragraph.a['href']) #append link if it's there\n",
    "        except:\n",
    "            continue\n",
    "        source_link.append('No link') #Append 'no link' if there's no url. \n",
    "                                        #Is this how we wanna do it??\n",
    "            \n",
    "    sources = list(zip(source_body,source_link))\n",
    "\n",
    "    return [tags, sub_header,text_body,sources, quote_href]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_articles(list_of_url: list) -> list:\n",
    "    \"\"\"\n",
    "    A function that scrapes relevant data from politifact.com. \\n\n",
    "\n",
    "    Input:\n",
    "    - - - - - - - -\n",
    "    list_of_url (list) : A list of URL's for each article to scrape. \\n\n",
    "    \n",
    "    Returns:\n",
    "    - - - - - - - -\n",
    "    list_of_dfs (list) : A list of of dataframe for each article.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    list_of_dfs = []\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for article_url in list_of_url: \n",
    "        article = get_soup(article_url, header=header) #Get BeautifulSoup element for each article\n",
    "        article_data = get_article_data(article) #Extract data from article\n",
    "        output.append(article_data) #Append data to output list\n",
    "    \n",
    "        output_df = pd.DataFrame(data=output, columns=['tags', 'sub_header', 'text_body', 'sources', 'quote_href']) #Convert to DataFrame\n",
    "\n",
    "    #list_of_dfs.append(output_df) \n",
    "    # \n",
    "    # Maybe append DataFrame to list of DataFrames? So it can save data along the way...\n",
    "\n",
    "    return output_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>sub_header</th>\n",
       "      <th>text_body</th>\n",
       "      <th>sources</th>\n",
       "      <th>quote_href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'/factchecks/2015/may/03/robert-hurt/hurt-ami...</td>\n",
       "      <td>\\nHurt amiss in blaming estate tax for sales o...</td>\n",
       "      <td>U.S. Rep. Robert Hurt full-heartedly joined hi...</td>\n",
       "      <td>[(U.S. Rep. Robert Hurt, \"Robert Hurt Votes to...</td>\n",
       "      <td>/factchecks/2015/may/03/robert-hurt/hurt-amiss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'/factchecks/2015/may/01/marco-rubio/iran-uni...</td>\n",
       "      <td>\\nDo Iran and the United States disagree on th...</td>\n",
       "      <td>How can the United States and Iran come to a d...</td>\n",
       "      <td>[(NPR, \"Transcript: NPR's Full Interview With ...</td>\n",
       "      <td>/factchecks/2015/may/01/marco-rubio/iran-unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'/factchecks/2015/may/01/city-atlanta/Studio-...</td>\n",
       "      <td>\\nStudio plan jobs claim misleading\\n</td>\n",
       "      <td>Atlanta officials say they are likely only wee...</td>\n",
       "      <td>[(\"Mayor Kasim Reed Announces Historic Redevel...</td>\n",
       "      <td>/factchecks/2015/may/01/city-atlanta/Studio-pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'/factchecks/2015/apr/30/representus/did-lawm...</td>\n",
       "      <td>\\nDid lawmakers who voted to keep defense-surp...</td>\n",
       "      <td>The recent unrest in Baltimore following the d...</td>\n",
       "      <td>[(Represent.us, meme, April 2015, https://scon...</td>\n",
       "      <td>/factchecks/2015/apr/30/representus/did-lawmak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'/factchecks/2015/apr/30/steve-crisafulli/cri...</td>\n",
       "      <td>\\nCrisafulli says 257,000 would be 'forced int...</td>\n",
       "      <td>Even before the Florida House adjourned early,...</td>\n",
       "      <td>[(Tampa Bay Times, \"Crisafulli: Why the Florid...</td>\n",
       "      <td>/factchecks/2015/apr/30/steve-crisafulli/crisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'/factchecks/2015/apr/30/david-clarke-jr/kill...</td>\n",
       "      <td>\\nKiller was on street after serving 2 years o...</td>\n",
       "      <td>Although his department’s primary activity is ...</td>\n",
       "      <td>[(WISN-TV, \"Upfront with Mike Gousha\" intervie...</td>\n",
       "      <td>/factchecks/2015/apr/30/david-clarke-jr/killer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'/factchecks/2015/apr/30/ben-carson/ben-carso...</td>\n",
       "      <td>\\nBen Carson says U.S. spending on health care...</td>\n",
       "      <td>As a world-renowned neurosurgeon who’s conside...</td>\n",
       "      <td>[(OECD, \"Total expenditure on health per capit...</td>\n",
       "      <td>/factchecks/2015/apr/30/ben-carson/ben-carson-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'/factchecks/2015/apr/30/rose-mary-grant/rose...</td>\n",
       "      <td>\\nRose Mary Grant says R.I. charter schools ‘o...</td>\n",
       "      <td>The subject of charter schools — the state mon...</td>\n",
       "      <td>[(ProvidenceJournal.com, \"R.I. foolish to harm...</td>\n",
       "      <td>/factchecks/2015/apr/30/rose-mary-grant/rose-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'/factchecks/2015/apr/29/nation-islam-researc...</td>\n",
       "      <td>\\nNation of Islam group says Israeli security ...</td>\n",
       "      <td>We’ve seen plenty of claims in recent days abo...</td>\n",
       "      <td>[(Nation of Islam Research, tweet, April 26, 2...</td>\n",
       "      <td>/factchecks/2015/apr/29/nation-islam-research-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'/factchecks/2015/apr/29/rush-limbaugh/rush-l...</td>\n",
       "      <td>\\nRush Limbaugh says Clinton Foundation spends...</td>\n",
       "      <td>Much of the discussion about the Clinton famil...</td>\n",
       "      <td>[(Rush Limbaugh, transcript of radio show, Apr...</td>\n",
       "      <td>/factchecks/2015/apr/29/rush-limbaugh/rush-lim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tags  \\\n",
       "0  {'/factchecks/2015/may/03/robert-hurt/hurt-ami...   \n",
       "1  {'/factchecks/2015/may/01/marco-rubio/iran-uni...   \n",
       "2  {'/factchecks/2015/may/01/city-atlanta/Studio-...   \n",
       "3  {'/factchecks/2015/apr/30/representus/did-lawm...   \n",
       "4  {'/factchecks/2015/apr/30/steve-crisafulli/cri...   \n",
       "5  {'/factchecks/2015/apr/30/david-clarke-jr/kill...   \n",
       "6  {'/factchecks/2015/apr/30/ben-carson/ben-carso...   \n",
       "7  {'/factchecks/2015/apr/30/rose-mary-grant/rose...   \n",
       "8  {'/factchecks/2015/apr/29/nation-islam-researc...   \n",
       "9  {'/factchecks/2015/apr/29/rush-limbaugh/rush-l...   \n",
       "\n",
       "                                          sub_header  \\\n",
       "0  \\nHurt amiss in blaming estate tax for sales o...   \n",
       "1  \\nDo Iran and the United States disagree on th...   \n",
       "2              \\nStudio plan jobs claim misleading\\n   \n",
       "3  \\nDid lawmakers who voted to keep defense-surp...   \n",
       "4  \\nCrisafulli says 257,000 would be 'forced int...   \n",
       "5  \\nKiller was on street after serving 2 years o...   \n",
       "6  \\nBen Carson says U.S. spending on health care...   \n",
       "7  \\nRose Mary Grant says R.I. charter schools ‘o...   \n",
       "8  \\nNation of Islam group says Israeli security ...   \n",
       "9  \\nRush Limbaugh says Clinton Foundation spends...   \n",
       "\n",
       "                                           text_body  \\\n",
       "0  U.S. Rep. Robert Hurt full-heartedly joined hi...   \n",
       "1  How can the United States and Iran come to a d...   \n",
       "2  Atlanta officials say they are likely only wee...   \n",
       "3  The recent unrest in Baltimore following the d...   \n",
       "4  Even before the Florida House adjourned early,...   \n",
       "5  Although his department’s primary activity is ...   \n",
       "6  As a world-renowned neurosurgeon who’s conside...   \n",
       "7  The subject of charter schools — the state mon...   \n",
       "8  We’ve seen plenty of claims in recent days abo...   \n",
       "9  Much of the discussion about the Clinton famil...   \n",
       "\n",
       "                                             sources  \\\n",
       "0  [(U.S. Rep. Robert Hurt, \"Robert Hurt Votes to...   \n",
       "1  [(NPR, \"Transcript: NPR's Full Interview With ...   \n",
       "2  [(\"Mayor Kasim Reed Announces Historic Redevel...   \n",
       "3  [(Represent.us, meme, April 2015, https://scon...   \n",
       "4  [(Tampa Bay Times, \"Crisafulli: Why the Florid...   \n",
       "5  [(WISN-TV, \"Upfront with Mike Gousha\" intervie...   \n",
       "6  [(OECD, \"Total expenditure on health per capit...   \n",
       "7  [(ProvidenceJournal.com, \"R.I. foolish to harm...   \n",
       "8  [(Nation of Islam Research, tweet, April 26, 2...   \n",
       "9  [(Rush Limbaugh, transcript of radio show, Apr...   \n",
       "\n",
       "                                          quote_href  \n",
       "0  /factchecks/2015/may/03/robert-hurt/hurt-amiss...  \n",
       "1  /factchecks/2015/may/01/marco-rubio/iran-unite...  \n",
       "2  /factchecks/2015/may/01/city-atlanta/Studio-pl...  \n",
       "3  /factchecks/2015/apr/30/representus/did-lawmak...  \n",
       "4  /factchecks/2015/apr/30/steve-crisafulli/crisa...  \n",
       "5  /factchecks/2015/apr/30/david-clarke-jr/killer...  \n",
       "6  /factchecks/2015/apr/30/ben-carson/ben-carson-...  \n",
       "7  /factchecks/2015/apr/30/rose-mary-grant/rose-m...  \n",
       "8  /factchecks/2015/apr/29/nation-islam-research-...  \n",
       "9  /factchecks/2015/apr/29/rush-limbaugh/rush-lim...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's give it a spin for the first 10 articles\n",
    "article_url_list = []\n",
    "url_base = 'https://politifact.com'\n",
    "\n",
    "for quote_href in data_full['quote_href']:\n",
    "    article_url_list.append(url_base+quote_href)\n",
    "\n",
    "get_all_articles(article_url_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "054e95b4819972eba8d406807e822e3be9cca805528e86310f8e3ac8dc287778"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
